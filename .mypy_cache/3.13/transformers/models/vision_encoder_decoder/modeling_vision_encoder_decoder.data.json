{".class":"MypyFile","_fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder","future_import_flags":[],"is_partial_stub_package":false,"is_stub":false,"names":{".class":"SymbolTable","AutoConfig":{".class":"SymbolTableNode","cross_ref":"transformers.models.auto.configuration_auto.AutoConfig","kind":"Gdef","module_public":false},"AutoModel":{".class":"SymbolTableNode","cross_ref":"transformers.models.auto.modeling_auto.AutoModel","kind":"Gdef","module_public":false},"AutoModelForCausalLM":{".class":"SymbolTableNode","cross_ref":"transformers.models.auto.modeling_auto.AutoModelForCausalLM","kind":"Gdef","module_public":false},"BaseModelOutput":{".class":"SymbolTableNode","cross_ref":"transformers.modeling_outputs.BaseModelOutput","kind":"Gdef","module_public":false},"GenerationMixin":{".class":"SymbolTableNode","cross_ref":"transformers.generation.utils.GenerationMixin","kind":"Gdef","module_public":false},"Optional":{".class":"SymbolTableNode","cross_ref":"typing.Optional","kind":"Gdef","module_public":false},"PreTrainedModel":{".class":"SymbolTableNode","cross_ref":"transformers.modeling_utils.PreTrainedModel","kind":"Gdef","module_public":false},"PretrainedConfig":{".class":"SymbolTableNode","cross_ref":"transformers.configuration_utils.PretrainedConfig","kind":"Gdef","module_public":false},"Seq2SeqLMOutput":{".class":"SymbolTableNode","cross_ref":"transformers.modeling_outputs.Seq2SeqLMOutput","kind":"Gdef","module_public":false},"Union":{".class":"SymbolTableNode","cross_ref":"typing.Union","kind":"Gdef","module_public":false},"VisionEncoderDecoderConfig":{".class":"SymbolTableNode","cross_ref":"transformers.models.vision_encoder_decoder.configuration_vision_encoder_decoder.VisionEncoderDecoderConfig","kind":"Gdef","module_public":false},"VisionEncoderDecoderModel":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"TypeInfo","_promote":[],"abstract_attributes":[],"alt_promote":null,"bases":["transformers.modeling_utils.PreTrainedModel","transformers.generation.utils.GenerationMixin"],"dataclass_transform_spec":null,"declared_metaclass":null,"defn":{".class":"ClassDef","fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel","name":"VisionEncoderDecoderModel","type_vars":[]},"deletable_attributes":[],"deprecated":null,"flags":[],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel","has_param_spec_type":false,"metaclass_type":null,"metadata":{},"module_name":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder","mro":["transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel","transformers.modeling_utils.PreTrainedModel","torch.nn.modules.module.Module","transformers.modeling_utils.ModuleUtilsMixin","transformers.utils.hub.PushToHubMixin","transformers.integrations.peft.PeftAdapterMixin","transformers.generation.utils.GenerationMixin","transformers.generation.continuous_batching.ContinuousMixin","builtins.object"],"names":{".class":"SymbolTable","__init__":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1,1,1],"arg_names":["self","config","encoder","decoder"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.__init__","name":"__init__","type":{".class":"CallableType","arg_kinds":[0,1,1,1],"arg_names":["self","config","encoder","decoder"],"arg_types":["transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel",{".class":"UnionType","items":["transformers.configuration_utils.PretrainedConfig",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["transformers.modeling_utils.PreTrainedModel",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["transformers.modeling_utils.PreTrainedModel",{".class":"NoneType"}],"uses_pep604_syntax":false}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"__init__ of VisionEncoderDecoderModel","ret_type":{".class":"NoneType"},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"_reorder_cache":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0],"arg_names":["self","past_key_values","beam_idx"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel._reorder_cache","name":"_reorder_cache","type":null}},"_supports_flash_attn_2":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_inferred","has_explicit_value"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel._supports_flash_attn_2","name":"_supports_flash_attn_2","type":"builtins.bool"}},"_supports_param_buffer_assignment":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_ready","is_inferred","has_explicit_value"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel._supports_param_buffer_assignment","name":"_supports_param_buffer_assignment","type":"builtins.bool"}},"_supports_sdpa":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_inferred","has_explicit_value"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel._supports_sdpa","name":"_supports_sdpa","type":"builtins.bool"}},"base_model_prefix":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_inferred","has_explicit_value"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.base_model_prefix","name":"base_model_prefix","type":"builtins.str"}},"config_class":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_inferred","has_explicit_value"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.config_class","name":"config_class","type":null}},"decoder":{".class":"SymbolTableNode","implicit":true,"kind":"Mdef","node":{".class":"Var","flags":["is_inferred"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.decoder","name":"decoder","type":{".class":"UnionType","items":["transformers.modeling_utils.PreTrainedModel",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1}],"uses_pep604_syntax":false}}},"enc_to_dec_proj":{".class":"SymbolTableNode","implicit":true,"kind":"Mdef","node":{".class":"Var","flags":["is_inferred"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.enc_to_dec_proj","name":"enc_to_dec_proj","type":"torch.nn.modules.linear.Linear"}},"encoder":{".class":"SymbolTableNode","implicit":true,"kind":"Mdef","node":{".class":"Var","flags":["is_inferred"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.encoder","name":"encoder","type":{".class":"UnionType","items":["transformers.modeling_utils.PreTrainedModel",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1}],"uses_pep604_syntax":false}}},"forward":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Decorator","func":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1,1,1,1,1,1,1,1,1,1,1,4],"arg_names":["self","pixel_values","decoder_input_ids","decoder_attention_mask","encoder_outputs","past_key_values","decoder_inputs_embeds","labels","use_cache","output_attentions","output_hidden_states","return_dict","kwargs"],"dataclass_transform_spec":null,"deprecated":null,"flags":["is_decorated"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.forward","name":"forward","type":{".class":"CallableType","arg_kinds":[0,1,1,1,1,1,1,1,1,1,1,1,4],"arg_names":["self","pixel_values","decoder_input_ids","decoder_attention_mask","encoder_outputs","past_key_values","decoder_inputs_embeds","labels","use_cache","output_attentions","output_hidden_states","return_dict","kwargs"],"arg_types":["transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel",{".class":"UnionType","items":["torch._C.FloatTensor",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["torch._C.LongTensor",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["torch._C.BoolTensor",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":[{".class":"TupleType","implicit":false,"items":["torch._C.FloatTensor"],"partial_fallback":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.tuple"}},{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":[{".class":"TupleType","implicit":false,"items":[{".class":"TupleType","implicit":false,"items":["torch._C.FloatTensor"],"partial_fallback":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.tuple"}}],"partial_fallback":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.tuple"}},{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["torch._C.FloatTensor",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["torch._C.LongTensor",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["builtins.bool",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["builtins.bool",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["builtins.bool",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["builtins.bool",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1}],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"forward of VisionEncoderDecoderModel","ret_type":{".class":"UnionType","items":[{".class":"TupleType","implicit":false,"items":["torch._C.FloatTensor"],"partial_fallback":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.tuple"}},"transformers.modeling_outputs.Seq2SeqLMOutput"],"uses_pep604_syntax":false},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}},"is_overload":false,"var":{".class":"Var","flags":["is_initialized_in_class","is_ready","is_inferred"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.forward","name":"forward","type":{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1}}}},"from_encoder_decoder_pretrained":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Decorator","func":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,1,1,2,4],"arg_names":["cls","encoder_pretrained_model_name_or_path","decoder_pretrained_model_name_or_path","model_args","kwargs"],"dataclass_transform_spec":null,"deprecated":null,"flags":["is_class","is_decorated"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.from_encoder_decoder_pretrained","name":"from_encoder_decoder_pretrained","type":{".class":"CallableType","arg_kinds":[0,1,1,2,4],"arg_names":["cls","encoder_pretrained_model_name_or_path","decoder_pretrained_model_name_or_path","model_args","kwargs"],"arg_types":[{".class":"TypeType","item":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel"},{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1}],"bound_args":[],"def_extras":{"first_arg":"cls"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"from_encoder_decoder_pretrained of VisionEncoderDecoderModel","ret_type":"transformers.modeling_utils.PreTrainedModel","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}},"is_overload":false,"var":{".class":"Var","flags":["is_initialized_in_class","is_classmethod","is_ready","is_inferred"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.from_encoder_decoder_pretrained","name":"from_encoder_decoder_pretrained","type":{".class":"CallableType","arg_kinds":[0,1,1,2,4],"arg_names":["cls","encoder_pretrained_model_name_or_path","decoder_pretrained_model_name_or_path","model_args","kwargs"],"arg_types":[{".class":"TypeType","item":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel"},{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":false},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1}],"bound_args":[],"def_extras":{"first_arg":"cls"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"from_encoder_decoder_pretrained of VisionEncoderDecoderModel","ret_type":"transformers.modeling_utils.PreTrainedModel","type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"from_pretrained":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Decorator","func":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,2,4],"arg_names":["cls","pretrained_model_name_or_path","model_args","kwargs"],"dataclass_transform_spec":null,"deprecated":null,"flags":["is_class","is_decorated"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.from_pretrained","name":"from_pretrained","type":null},"is_overload":false,"var":{".class":"Var","flags":["is_initialized_in_class","is_classmethod","is_ready","is_inferred"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.from_pretrained","name":"from_pretrained","type":{".class":"CallableType","arg_kinds":[0,0,2,4],"arg_names":["cls","pretrained_model_name_or_path","model_args","kwargs"],"arg_types":[{".class":"TypeType","item":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel"},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1},{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1}],"bound_args":[],"def_extras":{"first_arg":"cls"},"fallback":"builtins.function","from_concatenate":false,"implicit":true,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"from_pretrained of VisionEncoderDecoderModel","ret_type":{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}}},"get_decoder":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.get_decoder","name":"get_decoder","type":null}},"get_encoder":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.get_encoder","name":"get_encoder","type":null}},"get_input_embeddings":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.get_input_embeddings","name":"get_input_embeddings","type":null}},"get_output_embeddings":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0],"arg_names":["self"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.get_output_embeddings","name":"get_output_embeddings","type":null}},"main_input_name":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_inferred","has_explicit_value"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.main_input_name","name":"main_input_name","type":"builtins.str"}},"prepare_decoder_input_ids_from_labels":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","labels"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.prepare_decoder_input_ids_from_labels","name":"prepare_decoder_input_ids_from_labels","type":{".class":"CallableType","arg_kinds":[0,0],"arg_names":["self","labels"],"arg_types":["transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel","torch._tensor.Tensor"],"bound_args":[],"def_extras":{"first_arg":"self"},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"prepare_decoder_input_ids_from_labels of VisionEncoderDecoderModel","ret_type":{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"set_output_embeddings":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0],"arg_names":["self","new_embeddings"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.set_output_embeddings","name":"set_output_embeddings","type":null}},"supports_gradient_checkpointing":{".class":"SymbolTableNode","kind":"Mdef","node":{".class":"Var","flags":["is_initialized_in_class","is_inferred","has_explicit_value"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.supports_gradient_checkpointing","name":"supports_gradient_checkpointing","type":"builtins.bool"}}},"self_type":{".class":"TypeVarType","default":{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":4},"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.Self","id":0,"name":"Self","namespace":"","upper_bound":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel","values":[],"variance":0},"slots":null,"tuple_type":null,"type_vars":[],"typeddict_type":null}},"__all__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.__all__","name":"__all__","type":{".class":"Instance","args":["builtins.str"],"extra_attrs":null,"type_ref":"builtins.list"}}},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_ready"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"auto_docstring":{".class":"SymbolTableNode","cross_ref":"transformers.utils.args_doc.auto_docstring","kind":"Gdef","module_public":false},"gc":{".class":"SymbolTableNode","cross_ref":"gc","kind":"Gdef","module_public":false},"logger":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.logger","name":"logger","type":"logging.Logger"}},"logging":{".class":"SymbolTableNode","cross_ref":"transformers.utils.logging","kind":"Gdef","module_public":false},"nn":{".class":"SymbolTableNode","cross_ref":"torch.nn","kind":"Gdef","module_public":false},"os":{".class":"SymbolTableNode","cross_ref":"os","kind":"Gdef","module_public":false},"shift_tokens_right":{".class":"SymbolTableNode","kind":"Gdef","module_public":false,"node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0],"arg_names":["input_ids","pad_token_id","decoder_start_token_id"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.shift_tokens_right","name":"shift_tokens_right","type":{".class":"CallableType","arg_kinds":[0,0,0],"arg_names":["input_ids","pad_token_id","decoder_start_token_id"],"arg_types":["torch._tensor.Tensor","builtins.int","builtins.int"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"shift_tokens_right","ret_type":{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":1},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"tempfile":{".class":"SymbolTableNode","cross_ref":"tempfile","kind":"Gdef","module_public":false},"torch":{".class":"SymbolTableNode","cross_ref":"torch","kind":"Gdef","module_public":false}},"path":"/Users/hz/Projects/python/nsfw/.venv/lib/python3.13/site-packages/transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py"}